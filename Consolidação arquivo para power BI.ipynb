{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df796427",
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip install pyarrow\n",
    "import pandas as pd\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6350762",
   "metadata": {},
   "source": [
    "# Input usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0584051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input do usuario: Meses desesjados no DF\n",
    "\n",
    "Movs = [202204,202205,202206,202304,202305,202306]\n",
    "caminho = r\"\\\\srv-ameixa\\Setores2\\Gerenciamento de Categorias\\00. NOVO GC\\Bases\\Base_de_Vendas\\Base_de_Vendas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bd36c",
   "metadata": {},
   "source": [
    "# Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2febf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando objetos\n",
    "df = pd.DataFrame()\n",
    "df_atual = pd.DataFrame()\n",
    "csv_files = []\n",
    "\n",
    "#Criando lista dos caminhos dos arquivos. Um arquivo por mov no input dado pelo usuario \"Movs\"\n",
    "for mov in Movs:          \n",
    "    filename = caminho + \"_\"+ str(mov) + '.csv'\n",
    "    csv_files.append(filename)\n",
    "\n",
    "# Adcionando Cabeçalho aos arquivos e lendo todos os arquivos de uma vez (variavel df)  \n",
    "header_row = ['ANO_MES', 'UF', 'FLG_SAME_STORE_SALE', 'COD_LOJA_SAP', 'NOM_LOJA', 'REGIAO', 'NOM_DEPARTAMENTO', \n",
    "          'NOM_SECAO', 'NOM_CATEGORIA', 'NOM_SUBCATEGORIA', 'COD_PRODUTO', 'NOM_PRODUTO', 'EAN',\n",
    "          'RB', 'RL', 'VOL', 'CMV', 'LB']\n",
    "df = pd.concat([pd.read_csv(file, header=None, sep=';',names=header_row) for file in csv_files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9411f5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateus.craveiro\\AppData\\Local\\Temp\\ipykernel_12772\\637552700.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df[col] = df[col].str.replace(',',\"\").str.replace('.','')\n"
     ]
    }
   ],
   "source": [
    "#Tratamento colunas numericas\n",
    "colunas_numericas = ['RB','RL','VOL','CMV','LB']\n",
    "for col in colunas_numericas:\n",
    "    df[col] = df[col].str.replace(',',\"\").str.replace('.','')\n",
    "    #df[col] = df[col].astype(float)\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "    df[col] = df[col].apply(lambda x: x/100).astype(float)\n",
    "    \n",
    "    \n",
    "#Tratamento EAN\n",
    "df.drop('EAN', axis=1, inplace=True)\n",
    "#df['EAN'] = df['EAN'].apply(lambda x: '{:.0f}'.format(x))\n",
    "\n",
    "#Tratamento colunas categoricas\n",
    "colunas_categoricas = ['UF','COD_LOJA_SAP','NOM_LOJA','NOM_DEPARTAMENTO','NOM_SECAO',\n",
    "                       'NOM_CATEGORIA','NOM_SUBCATEGORIA','REGIAO']\n",
    "for col in colunas_categoricas:\n",
    "    df[col] = pd.Categorical(df[col])\n",
    "    \n",
    "#Tratamento colunas booleanas\n",
    "df['FLG_SAME_STORE_SALE'] = df['FLG_SAME_STORE_SALE'].map({'SIM': True, 'NÃO': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1759cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract 1 year from ANO_MES to get the previous year\n",
    "df['ANO_MES_LY'] = df['ANO_MES'] - 100\n",
    "\n",
    "\n",
    "# Merge the previous year's values to the original DataFrame\n",
    "df_ly = df.merge(df[['ANO_MES', 'COD_LOJA_SAP', 'COD_PRODUTO', 'RB', 'RL', 'VOL', 'LB']],\n",
    "                 left_on=['ANO_MES_LY', 'COD_LOJA_SAP', 'COD_PRODUTO'],\n",
    "                 right_on=['ANO_MES', 'COD_LOJA_SAP', 'COD_PRODUTO'],\n",
    "                 suffixes=('', '_LY'), how='left')\n",
    "\n",
    "df_SSS = df.copy()\n",
    "## Add the calculated columns RB_LY, RL_LY, VOL_LY, and LB_LY\n",
    "df_SSS['RB_LY'] = df_ly['RB_LY']\n",
    "df_SSS['RL_LY'] = df_ly['RL_LY']\n",
    "df_SSS['VOL_LY'] = df_ly['VOL_LY']\n",
    "df_SSS['LB_LY'] = df_ly['LB_LY']\n",
    "\n",
    "df_SSS = df_SSS.dropna(subset=['RB_LY','VOL_LY','LB_LY','RL_LY'],axis = 0,how = 'any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5888d",
   "metadata": {},
   "source": [
    "# Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e273cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146556845.82000002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SSS.query('ANO_MES == 202305').RB.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "930f21b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146556845.82000002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SSS.query('ANO_MES == 202305').RB.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6c22453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11982728.270000003"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validar com BI\n",
    "\n",
    "df.query('ANO_MES == 202305').RB.sum()\n",
    "df.query('ANO_MES == 202305').VOL.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5ea9f",
   "metadata": {},
   "source": [
    "# Exportando arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e309dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle(caminho + \"Base_de_Vendas.pkl\")\n",
    "#df.to_csv(caminho + \"Base_de_Venadas.csv\")\n",
    "#df.to_parquet(caminho + \".parquet\")\n",
    "df.to_parquet(caminho+\"_3meses\" + \".parquet\")\n",
    "#df.to_feather(caminho + \"Base_de_Vendas.feather\")\n",
    "df_SSS.to_parquet(caminho+\"_SSS_3meses\" + \".parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
